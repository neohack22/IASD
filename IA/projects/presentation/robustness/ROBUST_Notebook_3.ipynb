{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neohack22/IASD/blob/IA/IA/projects/presentation/robustness/ROBUST_Notebook_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiY3BiAiTRHK"
      },
      "source": [
        "## From adversarial examples to training robust models\n",
        "\n",
        "In the previous notebooks, we focused on methods for solving the maximization problem over perturbations; that is, to finding the solution to the problem\n",
        "\\begin{equation}\n",
        "\\DeclareMathOperator*{\\maximize}{maximize}\n",
        "\\maximize_{\\|\\delta\\| \\leq \\epsilon} \\ell(h_\\theta(x + \\delta), y).\n",
        "\\end{equation}\n",
        "\n",
        "In this notebook, we will focus on training a robust classifier. More precisly, we aim at solving following minimization problem, namely Adversarial Training:\n",
        "\\begin{equation}\n",
        "\\DeclareMathOperator*{\\minimize}{minimize}\n",
        "\\minimize_\\theta \\frac{1}{|S|} \\sum_{x,y \\in S} \\max_{\\|\\delta\\| \\leq \\epsilon} \\ell(h_\\theta(x + \\delta), y).\n",
        "\\end{equation}\n",
        "The order of the min-max operations is important here.  Specially, the max is inside the minimization, meaning that the adversary (trying to maximize the loss) gets to \"move\" _second_.  We assume, essentially, that the adversary has full knowledge of the classifier parameters $\\theta$, and that they get to specialize their attack to whatever parameters we have chosen in the outer minimization. The goal of the robust optimization formulation, therefore, is to ensure that the model cannot be attacked _even if_ the adversary has full knowledge of the model.  Of course, in practice we may want to make assumptions about the power of the adversary but it can be difficult to pin down a precise definition of what we mean by the \"power\" of the adversary, so extra care should be taken in evaluating models against possible \"realistic\" adversaries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QMXb08jTRHL"
      },
      "source": [
        "## Exercice 1\n",
        "1. Train a robust classifier using Adversarial Training with a specific norm\n",
        "2. Evaluate your classifier on natural and adversarial examples crafted with the norm of the training and other norms\n",
        "3. Make an analysis and conclude"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import time\n",
        "cuda = torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "VEf4gzjr_bF7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train a robust classifier using Adversarial Training with a specific norm"
      ],
      "metadata": {
        "id": "487phfmYXXyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all,  we are going to train our model:\n",
        "- on normal images\n",
        "- on attacked images\n",
        "\n",
        "Then we willl attack both with the ℓ∞ norm.\n",
        "\n",
        "Eventually we will tackle the use of other norms.\n",
        "\n"
      ],
      "metadata": {
        "id": "jc55WX9FnIMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load CIFAR10 dataset\n",
        "def load_cifar(split, batch_size):\n",
        "  train = True if split == 'train' else False\n",
        "  dataset = datasets.CIFAR10(\"./docs\", train=train, download=True, transform=transforms.ToTensor())\n",
        "  return DataLoader(dataset, batch_size=batch_size, shuffle=train)\n",
        "\n",
        "batch_size = 100\n",
        "train_loader = load_cifar('train', batch_size)\n",
        "test_loader = load_cifar('test', batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "9d634c00696346aca38baa0a9eebf03d",
            "bd4798d302aa496290401365bcdc13a9",
            "c66cbe1775514a9898c59b056a0643a9",
            "7ad99065ba754436828461b9fc32059b",
            "d5622a449d4341689567240a26332197",
            "5a38aba5ec1a4c6f919d8b29bb36a4f8",
            "5b218065721541b0800186de949ad5dc",
            "6042d60951de49dd936aa4a6adb8bfc4",
            "aa9448745edd4d20b295ddefac558f74",
            "75aaca93ae924f5fa5eab3be20d6d143",
            "d06c367515574803b140d0d029105599"
          ]
        },
        "id": "q8Jr7uL4_bQB",
        "outputId": "8559ad55-e4e9-46f0-8521-3cb3813392f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./docs/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d634c00696346aca38baa0a9eebf03d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./docs/cifar-10-python.tar.gz to ./docs\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_loader.dataset))\n",
        "print(len(test_loader.dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTHzztv9AXOw",
        "outputId": "878e5df3-6152-4fed-9a06-fa7f57cfc413"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the image classes\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "5W5eRK-mApMR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's no need to apply the sotmax here because it will be in the cross entropy loss too."
      ],
      "metadata": {
        "id": "yawtBtWLYFZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvModel(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(ConvModel, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2,padding=0)\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "    self.lin1 = nn.Linear(64*64, 1000)\n",
        "    self.lin2 = nn.Linear(1000, 120)\n",
        "    self.lin3 = nn.Linear(120, 10)\n",
        "    self.d_out = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = torch.flatten(x, 1) # flatten necessary dim\n",
        "\n",
        "    \n",
        "    x = self.lin1(x)\n",
        "    x = self.relu(x)\n",
        "    x=  self.d_out(x)\n",
        "\n",
        "    x = self.lin2(x)\n",
        "    x = self.relu(x)\n",
        "    x=  self.d_out(x)\n",
        "    \n",
        "    x = self.lin3(x)\n",
        "    x=  self.d_out(x)\n",
        "    \n",
        "    return x    "
      ],
      "metadata": {
        "id": "yDd_Nf7QA3SY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProjectedGradientDescent:\n",
        "  def __init__(self, model, eps, alpha, num_iter):\n",
        "    # code here ...\n",
        "    self.model=model\n",
        "    self.eps=eps\n",
        "    self.alpha=alpha\n",
        "    self.num_iter=num_iter\n",
        "  def compute(self, X, y):\n",
        "    \"\"\" Construct PGD adversarial pertubration on the examples x.\"\"\"  \n",
        "    \"\"\" Construct Projected Gradient Descent adversarial examples on the examples X\"\"\"\n",
        "    delta = torch.zeros_like(X, requires_grad=True)\n",
        "    for t in range(self.num_iter):\n",
        "        loss = nn.CrossEntropyLoss()(self.model(X + delta), y)\n",
        "        loss.backward()\n",
        "        \n",
        "        delta.data = (\n",
        "            delta + X.shape[\n",
        "                0]*self.alpha*delta.grad.detach().sign()).clamp(\n",
        "                -self.eps,self.eps)\n",
        "        delta.grad.zero_()\n",
        "        \n",
        "    \n",
        "    attacked_images= X + delta.detach()\n",
        "    return attacked_images"
      ],
      "metadata": {
        "id": "4_zQxvOGDAgY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_normal (model, criterion, optimizer, loader, attack):\n",
        "  # training with normal images\n",
        "  # just to comapre it to the adversal model trained with real images\n",
        "  \"\"\"Function to train the model\"\"\"\n",
        "  model.train()\n",
        "  iter = 0\n",
        "  losses = []\n",
        "  valid_loss_min = np.Inf #to track the changes in the validation loss\n",
        "  last_loss_to_print = [] # This is just a convenient variable to print the loss across epochs\n",
        "  # Training the Model\n",
        "  for epoch in range(int(epochs)):\n",
        "      start_time  = time.time()\n",
        "\n",
        "      for batch_n, (images, labels) in enumerate(train_loader):\n",
        "          if cuda :\n",
        "              images, labels = images.cuda(), labels.cuda()\n",
        "          # Forward + Backward + Optimize\n",
        "          # Gradients are set equal to 0 at each epoch\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Obtaining the normal images\n",
        "          images_attacked=images\n",
        "\n",
        "          # Forward\n",
        "          outputs_attacked = model(images_attacked)\n",
        "          loss = criterion(outputs_attacked, labels)\n",
        "          # Backward\n",
        "          loss.backward()\n",
        "          # Optimize: We calculate the gradients with optimizer.step()\n",
        "          optimizer.step()\n",
        "          iter+=1\n",
        "          losses.append(loss)\n",
        "          last_loss_to_print = loss"
      ],
      "metadata": {
        "id": "fnzhClGOpfue"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iters = 10 \n",
        "epochs = 10 \n",
        "lr_rate = 0.01\n",
        "\n",
        "def adversarial_train_model(model, criterion, optimizer, loader, attack):\n",
        "  # adverserial training with PGD\n",
        "  \"\"\"Function to train the model\"\"\"\n",
        "  model.train()\n",
        "  iter = 0\n",
        "  losses = []\n",
        "  valid_loss_min = np.Inf #to track the changes in the validation loss\n",
        "  last_loss_to_print = [] # This is just a convenient variable to print the loss across epochs\n",
        "  # Training the Model\n",
        "  for epoch in range(int(epochs)):\n",
        "      start_time  = time.time()\n",
        "\n",
        "      for batch_n, (images, labels) in enumerate(train_loader):\n",
        "          if cuda :\n",
        "              images, labels = images.cuda(), labels.cuda()\n",
        "          # Forward + Backward + Optimize\n",
        "          # Gradients are set equal to 0 at each epoch\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Obtaining the attacked images\n",
        "          images_attacked=attack.compute(images,labels)\n",
        "\n",
        "          # Forward\n",
        "          outputs_attacked = model(images_attacked)\n",
        "          loss = criterion(outputs_attacked, labels)\n",
        "          # Backward\n",
        "          loss.backward()\n",
        "          # Optimize: We calculate the gradients with optimizer.step()\n",
        "          optimizer.step()\n",
        "          iter+=1\n",
        "          losses.append(loss)\n",
        "          last_loss_to_print = loss"
      ],
      "metadata": {
        "id": "F_aOaGgJDKI3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate your classifier on natural and adversarial examples crafted with the norm of the training and other norms"
      ],
      "metadata": {
        "id": "fkxWQYo-ZGBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We look at the normal model in order to make the comparison with the other model trained with attacked images."
      ],
      "metadata": {
        "id": "7qi1woNZY5bF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alpha has to be lower than epsilon: epsilon is what we want to explore and we do it through small steps of size alpha.<br>"
      ],
      "metadata": {
        "id": "bQP7NrK0Z133"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate Model Class\n",
        "model_normal = ConvModel()\n",
        "# move tensors to GPU if CUDA is available\n",
        "if cuda:\n",
        "  model_normal = model_normal.cuda()\n",
        "\n",
        "# define your loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = torch.optim.SGD(\n",
        "    model_normal.parameters(), lr=lr_rate, momentum =0.9)\n",
        "\n",
        "\n",
        "# define the attack\n",
        "attack = ProjectedGradientDescent(\n",
        "# We set num_iter=5 because with num_iter=20 tooks 2 min par epoch    \n",
        "    model_normal, eps=0.1, alpha=0.01, num_iter=5) \n",
        "\n",
        "# train the model robust to attack\n",
        "train_model_normal(\n",
        "    model_normal, criterion, optimizer, train_loader, attack)\n",
        "\n",
        "model_normal.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nowKxX2Iqh3N",
        "outputId": "3e462d77-2e59-4719-a240-855833d5845a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvModel(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu): ReLU()\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (lin1): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  (lin2): Linear(in_features=1000, out_features=120, bias=True)\n",
              "  (lin3): Linear(in_features=120, out_features=10, bias=True)\n",
              "  (d_out): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
        "# epsilon = .05\n",
        "def eval_model_underattack(model, loader, attack=None):\n",
        "  \"\"\"Function to evaluate your model on a specific loader\"\"\"\n",
        "\n",
        "  # Test the Model\n",
        "  # We set the model to evaluation mode with model.eval(). \n",
        "  # It disables any drop-out or batch normalization layers in model\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  correct_under_attack = 0\n",
        "  total = 0\n",
        "  for images, labels in test_loader:\n",
        "      if cuda :\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "      \n",
        "      # Set requires_grad attribute of tensor. Important for Attack\n",
        "      images.requires_grad = True\n",
        "      \n",
        "      # Classify the initial image (with no perturbation yet)\n",
        "      outputs = model(images)\n",
        "      _, predicted_label = torch.max(outputs.data, 1)\n",
        "      correct += (predicted_label == labels).sum().item()\n",
        "      # Calculate the loss\n",
        "      loss = criterion(outputs, labels)\n",
        "      # Zero all existing gradients\n",
        "      model.zero_grad()\n",
        "      # Backward\n",
        "      loss.backward()\n",
        "      # Collect images gradients\n",
        "      images_grad = images.grad.data\n",
        "      \n",
        "      # # Produce Attack\n",
        "      \n",
        "\n",
        "      # Obtaining the attacked images\n",
        "      images_attacked=attack.compute(images,labels)\n",
        "\n",
        "      # Re-classify the perturbed image\n",
        "      outputs = model(images_attacked)\n",
        "      _, attacked_label = torch.max(outputs.data, 1)\n",
        "      correct_under_attack += (attacked_label == labels).sum().item()\n",
        "\n",
        "      total += labels.size(0)\n",
        "      \n",
        "    \n",
        "  print(correct)\n",
        "  print(correct_under_attack)\n",
        "  print(total)\n",
        "  print(\n",
        "      'Accuracy of the model on the test images: %d %%' % (\n",
        "          100 * correct / total))\n",
        "  print(\n",
        "      'Accuracy of the model on the test images under attack: %d %%' % (\n",
        "          100 * correct_under_attack / total))"
      ],
      "metadata": {
        "id": "hcc5R4ZSD5qe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, loader, attack=None):\n",
        "  \"\"\"Function to evaluate your model on a specific loader\"\"\"\n",
        "  accuracy = 0.\n",
        "  n_inputs = 0.\n",
        "  for n_batch, (imgs, labels) in enumerate(loader):\n",
        "      if cuda:\n",
        "        imgs, labels = imgs.cuda(), labels.cuda()\n",
        "      if attack==None:\n",
        "        outputs = model(imgs)\n",
        "      else:\n",
        "        outputs = model(imgs + attack.compute(imgs, labels))\n",
        "      predicted = outputs.argmax(axis=1)\n",
        "      n_inputs += outputs.size(0)\n",
        "      accuracy += (predicted == labels).sum()\n",
        "  accuracy = accuracy/n_inputs\n",
        "  print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "hykUAH4TGXTE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_normal= ProjectedGradientDescent(model_normal, 0.03, 0.01, 10)\n",
        "attack = ProjectedGradientDescent(model, 0.03, 0.01, 10)\n",
        "\n",
        "# eval the normal modedl\n",
        "print(\"results on the normal model\")\n",
        "eval_model(model_normal, test_loader)\n",
        "eval_model(model_normal, test_loader, attack)\n",
        "\n",
        "# eval the attacked model\n",
        "print(\"results on the robust model\")\n",
        "eval_model(model, test_loader)\n",
        "eval_model(model, test_loader, attack)\n",
        "\n",
        "\n",
        "attack_normal= ProjectedGradientDescent(model_normal, 0.1, 0.0005, 10)\n",
        "attack = ProjectedGradientDescent(model, 0.1, 0.0005, 10)\n",
        "\n",
        "# eval the normal modedl\n",
        "print(\"results on the normal model\")\n",
        "eval_model(model_normal, test_loader)\n",
        "eval_model(model_normal, test_loader, attack)\n",
        "\n",
        "# eval the attacked model\n",
        "print(\"results on the robust model\")\n",
        "eval_model(model, test_loader)\n",
        "eval_model(model, test_loader, attack)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_vYUR7qpC1u",
        "outputId": "0c70e3fa-d9cf-4a31-f47c-37125b188f38"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "results on the normal model\n",
            "Accuracy:  tensor(0.7198, device='cuda:0')\n",
            "Accuracy:  tensor(0.6324, device='cuda:0')\n",
            "results on the robust model\n",
            "Accuracy:  tensor(0.2549, device='cuda:0')\n",
            "Accuracy:  tensor(0.1732, device='cuda:0')\n",
            "results on the normal model\n",
            "Accuracy:  tensor(0.7198, device='cuda:0')\n",
            "Accuracy:  tensor(0.5464, device='cuda:0')\n",
            "results on the robust model\n",
            "Accuracy:  tensor(0.2484, device='cuda:0')\n",
            "Accuracy:  tensor(0.1463, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train our models with the best parameters found."
      ],
      "metadata": {
        "id": "kTvXvG_CdjoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deal with the normal model in order to make the comparison with the other model trained with attacked images\n",
        "\n",
        "# Instantiate Model Class\n",
        "model_normal = ConvModel()\n",
        "# move tensors to GPU if CUDA is available\n",
        "if cuda:\n",
        "  model_normal = model_normal.cuda()\n",
        "\n",
        "# define your loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = torch.optim.SGD(\n",
        "    model_normal.parameters(), lr=lr_rate, momentum =0.9)\n",
        "\n",
        "\n",
        "# define the attack\n",
        "# Alpha has to be lower than epsilon: epsilon is the ball we want to explore\n",
        "# and we do it through small steps of size alpha\n",
        "# We set num_iter = 5 because with num_iter = 20 tooks 2 min par epoch\n",
        "attack = ProjectedGradientDescent(\n",
        "    model_normal, eps=0.1, alpha=0.0005, num_iter=10) \n",
        "\n",
        "# train the model robust to attack\n",
        "train_model_normal(\n",
        "    model_normal, criterion, optimizer, train_loader, attack)\n",
        "\n",
        "model_normal.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJOj6q2s7Qfe",
        "outputId": "2df5c475-32a2-4996-850f-f073a2c24cae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvModel(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu): ReLU()\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (lin1): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  (lin2): Linear(in_features=1000, out_features=120, bias=True)\n",
              "  (lin3): Linear(in_features=120, out_features=10, bias=True)\n",
              "  (d_out): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate Model Class\n",
        "model = ConvModel()\n",
        "# move tensors to GPU if CUDA is available\n",
        "if cuda:\n",
        "  model = model.cuda()\n",
        "\n",
        "# define your loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate, momentum =0.9)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# define the attack\n",
        "# Alpha has to be lower than epsilon: epsilon is the ball we want to explore\n",
        "# and we do it through small steps of size alpha\n",
        "# We set num_iter = 5 because with num_iter = 20 tooks 2 min par epoch\n",
        "attack = ProjectedGradientDescent(model, eps=0.1, alpha=0.0005, num_iter=10) \n",
        "\n",
        "# train the model robust to attack\n",
        "adversarial_train_model(model, criterion, optimizer, train_loader, attack)\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlqGXZ1F7QmV",
        "outputId": "841b12d8-f430-4a6e-b7d0-83bd2c24d555"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvModel(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu): ReLU()\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (lin1): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  (lin2): Linear(in_features=1000, out_features=120, bias=True)\n",
              "  (lin3): Linear(in_features=120, out_features=10, bias=True)\n",
              "  (d_out): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test now the attacks\n",
        "attack_normal= ProjectedGradientDescent(model_normal, 0.1, 0.0005, 10)\n",
        "attack = ProjectedGradientDescent(model, 0.1, 0.0005, 10)\n",
        "\n",
        "# eval the normal model\n",
        "print(\"results on the normal model\")\n",
        "eval_model(model_normal, test_loader)\n",
        "eval_model(model_normal, test_loader, attack)\n",
        "\n",
        "# eval the attacked model\n",
        "print(\"results on the robust model\")\n",
        "eval_model(model, test_loader)\n",
        "eval_model(model, test_loader, attack)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39PkX5BD7tIs",
        "outputId": "a6600a0a-da47-48b4-da34-ad0872a29473"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "results on the normal model\n",
            "Accuracy:  tensor(0.7135, device='cuda:0')\n",
            "Accuracy:  tensor(0.5841, device='cuda:0')\n",
            "results on the robust model\n",
            "Accuracy:  tensor(0.3174, device='cuda:0')\n",
            "Accuracy:  tensor(0.1935, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make an analysis and conclude"
      ],
      "metadata": {
        "id": "z3092IUscvcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Analysis:* "
      ],
      "metadata": {
        "id": "37Bkp4OXbD5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The smaller the step the smaller the accuracy.<br>\n",
        "The greatest epsilon is, the lesser the accuray.<br>\n",
        "For a given epilson, the higher the step, the less the accuracy.<br>\n",
        "Increasing iterations decreases accuracy to a certain level."
      ],
      "metadata": {
        "id": "CW7DuWOhk_uS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "attack_normal= ProjectedGradientDescent(model_normal, 0.03, 0.01, 10)\n",
        "attack=        ProjectedGradientDescent(model,        0.03, 0.01, 10)\n",
        "\n",
        "results on the normal model\n",
        "*   Accuracy without attack:  0.7198\n",
        "*   Accuracy with attack:     0.6324\n",
        "\n",
        "results on the robust model\n",
        "*   Accuracy without attack:  0.2549\n",
        "*   Accuracy with attack:     0.1732\n",
        "\n",
        "attack_normal= ProjectedGradientDescent(model_normal, 0.1, 0.0005, 10)\n",
        "attack=        ProjectedGradientDescent(model,        0.1, 0.0005, 10)\n",
        "\n",
        "results on the normal model\n",
        "*   Accuracy without attack:  0.7198\n",
        "*   Accuracy with attack:     0.5464\n",
        "\n",
        "results on the robust model\n",
        "*   Accuracy without attack:  0.2484\n",
        "*   Accuracy with attack:     0.1463\n",
        "```\n",
        "\n",
        "- The accuracy of the robust models are lower than the normal models'.<br>\n",
        "It's due to the fact that we indroduce noise when training with attacked images, which alters the weaker correlations.\n",
        "- Thus the parameters choosen are resulting from a trade off between accuracy vs robustness.\n",
        "- Yet when palying with parameters epsilon, alpha and iterations, we notice that the most efficient attack occurs with a smaller alpha, bringing the accuracy to 14% (for a given magnitude of epsilon being 0.1).\n",
        "\n",
        "As a consequence, we trained our modelds with the most efficient parameters to attack."
      ],
      "metadata": {
        "id": "U61WhCmMvE65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Conclusions:* \n",
        "\n",
        "**We see that the training has worked since the accuracy obtained increases from 14% to 17%.**<br>\n",
        "\n",
        "```\n",
        "results on the normal model\n",
        "Accuracy:  tensor(0.7135, device='cuda:0')\n",
        "Accuracy:  tensor(0.5841, device='cuda:0')\n",
        "results on the robust model\n",
        "Accuracy:  tensor(0.3174, device='cuda:0')\n",
        "Accuracy:  tensor(0.1935, device='cuda:0')\n",
        "```\n",
        "\n",
        "With additional data, we could imagine that the accuracy could be improved (adversarial models require more data than non adversarial ones).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Using a different kind of norm is explained in different publications. It implies:\n",
        "\n",
        "- the use of a larger epsilon values, because the volume of the ball is much smaller than with a ℓ∞ nrom\n",
        "- Choosing a higher epsilon can lead to have a more visible attack. One can ask itself what are the acceptable values of eppislon.\n",
        "- Litterature also says that with the ℓ∞ norm, the attack is spread within the images while with a l1 or l2 norm the attack is more on specific points or areas. This could lead also to the attack to be more noticed.\n",
        "\n"
      ],
      "metadata": {
        "id": "5mTFWcJf7-xX"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d634c00696346aca38baa0a9eebf03d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd4798d302aa496290401365bcdc13a9",
              "IPY_MODEL_c66cbe1775514a9898c59b056a0643a9",
              "IPY_MODEL_7ad99065ba754436828461b9fc32059b"
            ],
            "layout": "IPY_MODEL_d5622a449d4341689567240a26332197"
          }
        },
        "bd4798d302aa496290401365bcdc13a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a38aba5ec1a4c6f919d8b29bb36a4f8",
            "placeholder": "​",
            "style": "IPY_MODEL_5b218065721541b0800186de949ad5dc",
            "value": "100%"
          }
        },
        "c66cbe1775514a9898c59b056a0643a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6042d60951de49dd936aa4a6adb8bfc4",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa9448745edd4d20b295ddefac558f74",
            "value": 170498071
          }
        },
        "7ad99065ba754436828461b9fc32059b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75aaca93ae924f5fa5eab3be20d6d143",
            "placeholder": "​",
            "style": "IPY_MODEL_d06c367515574803b140d0d029105599",
            "value": " 170498071/170498071 [00:04&lt;00:00, 37979130.57it/s]"
          }
        },
        "d5622a449d4341689567240a26332197": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a38aba5ec1a4c6f919d8b29bb36a4f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b218065721541b0800186de949ad5dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6042d60951de49dd936aa4a6adb8bfc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa9448745edd4d20b295ddefac558f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75aaca93ae924f5fa5eab3be20d6d143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d06c367515574803b140d0d029105599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}