{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neohack22/IASD/blob/graphs/WS_22_01_DataLoadingAndExploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu59iJ3PGlWX"
      },
      "source": [
        "# Requirements\n",
        "\n",
        "If you have not created your Neo4J Sandbox yet, please run the pre-setup notebook to do sp."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoaqhgJQC_fC"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Install the necessary library in your Colab notebook environment and connect to your hosted Neo4J Sandbox."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmHymBmsVYqx"
      },
      "source": [
        "!pip install neo4j"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the connection details that "
      ],
      "metadata": {
        "id": "Qk3q1E45KJnn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhmJ1QEdC-4e"
      },
      "source": [
        "ip = \"54.174.38.179\"\n",
        "bolt_port = \"7687\"\n",
        "username = \"neo4j\"\n",
        "password = \"spots-carrier-wires\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI-e7X2UuOgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ad1843-024f-4513-9436-c0b57803e8f7"
      },
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "driver = GraphDatabase.driver(\"bolt://\" + ip + \":\" + bolt_port, auth=(username, password))\n",
        "\n",
        "print(driver.address) # your-sandbox-ip:your-sandbox-bolt-port"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54.174.38.179:7687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWqz69-VuOgQ"
      },
      "source": [
        "# Citation Dataset Loading\n",
        "\n",
        "In this notebook we're going to load the citation dataset into Neo4j."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXVLAZcyXe6v"
      },
      "source": [
        "## Reset database\n",
        "Ensure you start with a clean and empty database in your Sandbox (it may be pre-loaded with toy data). To do so, run the following cell to delete all nodes and relationships.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by1gXcnOXMP4",
        "outputId": "a7a0f715-51f7-4219-bb0a-56d462a2f702"
      },
      "source": [
        "query = \"\"\"\n",
        "  CALL apoc.periodic.iterate(\n",
        "    \"MATCH (n) RETURN n\", \n",
        "    \"DETACH DELETE n\", \n",
        "    {batchSize:1000}\n",
        "  )\n",
        "  yield batches, total return batches, total\n",
        "\"\"\"\n",
        "\n",
        "with driver.session() as session:\n",
        "  result = session.run(query)\n",
        "  for row in result:\n",
        "    print(row)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Record batches=133 total=132259>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's show now how to load a JSON file, and display each record.\n",
        "\n",
        "It is useful to expore records in order to understand theyr structure (name and type of attributes, etc. ). Of course you could use a schema inference tool, but this is beyond the scope of this lab. "
      ],
      "metadata": {
        "id": "HWt5I7xAd7f-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "CALL apoc.load.json(\"https://github.com/mneedham/link-prediction/raw/master/data/dblp-ref-0.json\")\n",
        "YIELD value WITH value\n",
        "RETURN value\n",
        "LIMIT 100;\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "with driver.session() as session:\n",
        "  result = session.run(query)\n",
        "  for row in result:\n",
        "    print(row)"
      ],
      "metadata": {
        "id": "YbuorACndJ4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's modify the above code in order to diplay records once some of the fields (\"id\", \"authors\", \"references\", \"venue\") have been discarded. "
      ],
      "metadata": {
        "id": "wtRwCXdAey1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "CALL apoc.load.json(\"https://github.com/mneedham/link-prediction/raw/master/data/dblp-ref-0.json\")\n",
        "YIELD value WITH  apoc.map.clean(value,[\"id\",\"authors\",\"references\", \"venue\"],[]) AS filtered\n",
        "RETURN filtered\n",
        "LIMIT 100;\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "with driver.session() as session:\n",
        "  result = session.run(query)\n",
        "  for row in result:\n",
        "    print(row)"
      ],
      "metadata": {
        "id": "OoOh5ajTeFdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNlvzmkbuOgU"
      },
      "source": [
        "## Create Constraints\n",
        "\n",
        "First let's create some constraints to make sure we won't import duplicate data. We basically use an attribute as an identifier for each type of node that we will create."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0zNkfh0uOgU"
      },
      "source": [
        "with driver.session() as session:\n",
        "    display(session.run(\"CREATE CONSTRAINT ON (a:Article) ASSERT a.index IS UNIQUE\").consume().counters)\n",
        "    display(session.run(\"CREATE CONSTRAINT ON (a:Author) ASSERT a.name IS UNIQUE\").consume().counters)\n",
        "    display(session.run(\"CREATE CONSTRAINT ON (v:Venue) ASSERT v.name IS UNIQUE\").consume().counters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8aTpOD9uOgV"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "Now let's load the data into the database. We will create nodes and relationships for *Articles*, *Venues*, and *Authors* from JSON files that represent an extract of the DBLP dataset. \n",
        "\n",
        "We will load/import 4 files so as to avoid overloading problems (othewise settings should be changed, typically the session timeout). \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first dataset\n",
        "\n",
        "query = \"\"\"\n",
        "CALL apoc.periodic.iterate(\n",
        "  'UNWIND [\"dblp-ref-0.json\"] AS file\n",
        "   CALL apoc.load.json(\"https://github.com/mneedham/link-prediction/raw/master/data/\" + file)\n",
        "   YIELD value WITH value\n",
        "   RETURN value',\n",
        "  'MERGE (a:Article {index:value.id})\n",
        "   SET a += apoc.map.clean(value,[\"id\",\"authors\",\"references\", \"venue\"],[0])\n",
        "   WITH a, value.authors as authors, value.references AS citations, value.venue AS venue\n",
        "   MERGE (v:Venue {name: venue})\n",
        "   MERGE (a)-[:VENUE]->(v)\n",
        "   FOREACH(author in authors | \n",
        "     MERGE (b:Author{name:author})\n",
        "     MERGE (a)-[:AUTHOR]->(b))\n",
        "   FOREACH(citation in citations | \n",
        "     MERGE (cited:Article {index:citation})\n",
        "     MERGE (a)-[:CITED]->(cited))', \n",
        "   {batchSize: 1000, iterateList: true});\n",
        "\"\"\"\n",
        "\n",
        "with driver.session() as session:\n",
        "    result = session.run(query)\n",
        "    for row in result:\n",
        "        print(row)"
      ],
      "metadata": {
        "id": "oVlwjunhC8EF",
        "outputId": "ed551988-3e74-4688-f2bd-05d8d740bdf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Record batches=25 total=24666 timeTaken=34 committedOperations=24666 failedOperations=0 failedBatches=0 retries=0 errorMessages={} batch={'total': 25, 'committed': 25, 'failed': 0, 'errors': {}} operations={'total': 24666, 'committed': 24666, 'failed': 0, 'errors': {}} wasTerminated=False failedParams={} updateStatistics={'nodesDeleted': 0, 'labelsAdded': 158066, 'relationshipsCreated': 256228, 'nodesCreated': 158066, 'propertiesSet': 250075, 'relationshipsDeleted': 0, 'labelsRemoved': 0}>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# second dataset\n",
        "\n",
        "query = \"\"\"\n",
        "CALL apoc.periodic.iterate(\n",
        "  'UNWIND [\"dblp-ref-1.json\"] AS file\n",
        "   CALL apoc.load.json(\"https://github.com/mneedham/link-prediction/raw/master/data/\" + file)\n",
        "   YIELD value WITH value\n",
        "   RETURN value',\n",
        "  'MERGE (a:Article {index:value.id})\n",
        "   SET a += apoc.map.clean(value,[\"id\",\"authors\",\"references\", \"venue\"],[0])\n",
        "   WITH a, value.authors as authors, value.references AS citations, value.venue AS venue\n",
        "   MERGE (v:Venue {name: venue})\n",
        "   MERGE (a)-[:VENUE]->(v)\n",
        "   FOREACH(author in authors | \n",
        "     MERGE (b:Author{name:author})\n",
        "     MERGE (a)-[:AUTHOR]->(b))\n",
        "   FOREACH(citation in citations | \n",
        "     MERGE (cited:Article {index:citation})\n",
        "     MERGE (a)-[:CITED]->(cited))', \n",
        "   {batchSize: 1000, iterateList: true});\n",
        "\"\"\"\n",
        "\n",
        "with driver.session() as session:\n",
        "    result = session.run(query)\n",
        "    for row in result:\n",
        "        print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY6kuLkhaf3r",
        "outputId": "cce1cb8c-bb66-40bc-f90f-4cbf100fa08a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Record batches=10 total=9506 timeTaken=12 committedOperations=9506 failedOperations=0 failedBatches=0 retries=0 errorMessages={} batch={'total': 10, 'committed': 10, 'failed': 0, 'errors': {}} operations={'total': 9506, 'committed': 9506, 'failed': 0, 'errors': {}} wasTerminated=False failedParams={} updateStatistics={'nodesDeleted': 0, 'labelsAdded': 42291, 'relationshipsCreated': 87333, 'nodesCreated': 42291, 'propertiesSet': 75929, 'relationshipsDeleted': 0, 'labelsRemoved': 0}>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# third dataset\n",
        "\n",
        "\n",
        "query = \"\"\"\n",
        "CALL apoc.periodic.iterate(\n",
        "  'UNWIND [\"dblp-ref-2.json\"] AS file\n",
        "   CALL apoc.load.json(\"https://github.com/mneedham/link-prediction/raw/master/data/\" + file)\n",
        "   YIELD value WITH value\n",
        "   RETURN value',\n",
        "  'MERGE (a:Article {index:value.id})\n",
        "   SET a += apoc.map.clean(value,[\"id\",\"authors\",\"references\", \"venue\"],[0])\n",
        "   WITH a, value.authors as authors, value.references AS citations, value.venue AS venue\n",
        "   MERGE (v:Venue {name: venue})\n",
        "   MERGE (a)-[:VENUE]->(v)\n",
        "   FOREACH(author in authors | \n",
        "     MERGE (b:Author{name:author})\n",
        "     MERGE (a)-[:AUTHOR]->(b))\n",
        "   FOREACH(citation in citations | \n",
        "     MERGE (cited:Article {index:citation})\n",
        "     MERGE (a)-[:CITED]->(cited))', \n",
        "   {batchSize: 1000, iterateList: true});\n",
        "\"\"\"\n",
        "\n",
        "with driver.session() as session:\n",
        "    result = session.run(query)\n",
        "    for row in result:\n",
        "        print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOTupYaPafMS",
        "outputId": "b8145c17-bb95-4994-ed80-4d3c2d4cd6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Record batches=14 total=13641 timeTaken=16 committedOperations=13641 failedOperations=0 failedBatches=0 retries=0 errorMessages={} batch={'total': 14, 'committed': 14, 'failed': 0, 'errors': {}} operations={'total': 13641, 'committed': 13641, 'failed': 0, 'errors': {}} wasTerminated=False failedParams={} updateStatistics={'nodesDeleted': 0, 'labelsAdded': 53696, 'relationshipsCreated': 119954, 'nodesCreated': 53696, 'propertiesSet': 100724, 'relationshipsDeleted': 0, 'labelsRemoved': 0}>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fourth dataset\n",
        "\n",
        "\n",
        "query = \"\"\"\n",
        "CALL apoc.periodic.iterate(\n",
        "  'UNWIND [\"dblp-ref-3.json\"] AS file\n",
        "   CALL apoc.load.json(\"https://github.com/mneedham/link-prediction/raw/master/data/\" + file)\n",
        "   YIELD value WITH value\n",
        "   RETURN value',\n",
        "  'MERGE (a:Article {index:value.id})\n",
        "   SET a += apoc.map.clean(value,[\"id\",\"authors\",\"references\", \"venue\"],[0])\n",
        "   WITH a, value.authors as authors, value.references AS citations, value.venue AS venue\n",
        "   MERGE (v:Venue {name: venue})\n",
        "   MERGE (a)-[:VENUE]->(v)\n",
        "   FOREACH(author in authors | \n",
        "     MERGE (b:Author{name:author})\n",
        "     MERGE (a)-[:AUTHOR]->(b))\n",
        "   FOREACH(citation in citations | \n",
        "     MERGE (cited:Article {index:citation})\n",
        "     MERGE (a)-[:CITED]->(cited))', \n",
        "   {batchSize: 1000, iterateList: true});\n",
        "\"\"\"\n",
        "\n",
        "with driver.session() as session:\n",
        "    result = session.run(query)\n",
        "    for row in result:\n",
        "        print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffeVgLcnatK5",
        "outputId": "eccdf4e7-87ac-4cd9-d2b4-6223a765f17d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Record batches=5 total=4143 timeTaken=3 committedOperations=4143 failedOperations=0 failedBatches=0 retries=0 errorMessages={} batch={'total': 5, 'committed': 5, 'failed': 0, 'errors': {}} operations={'total': 4143, 'committed': 4143, 'failed': 0, 'errors': {}} wasTerminated=False failedParams={} updateStatistics={'nodesDeleted': 0, 'labelsAdded': 10563, 'relationshipsCreated': 18924, 'nodesCreated': 10563, 'propertiesSet': 23610, 'relationshipsDeleted': 0, 'labelsRemoved': 0}>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osVOJT9YFNaq"
      },
      "source": [
        "Let's check/ensure that we did not create any *Article* without title."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY3LxcPpuOgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61479e72-f986-403a-dc76-71dc2906190e"
      },
      "source": [
        "query = \"\"\"\n",
        "  call apoc.periodic.iterate(\n",
        "    'MATCH (a:Article) WHERE not(exists(a.title)) RETURN a',\n",
        "    'DETACH DELETE a',\n",
        "    {batchSize:1000}\n",
        "  )\n",
        "  yield batches, total return batches, total\n",
        "\"\"\"\n",
        "\n",
        "with driver.session() as session:\n",
        "    result = session.run(query)\n",
        "    for row in result:\n",
        "        print(row)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Record batches=133 total=132357>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIzCuwhoFk8s"
      },
      "source": [
        "# Explore the data\n",
        "\n",
        "Let's use the intuitive Neo4J Browser to explore the data that we have imported using Cypher queries. To access the Browser, go to your Sandbox control panel (at https://sandbox.neo4j.com/) and click the *Open* button.\n",
        "\n",
        "Here are some queries left as exercise to explore your newly created DBLP database in the Neo4J Browser. Various solutions are valid for each question. Hint: use the \"LIMIT\" clause to avoid returning too many results and slowing down your queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnN_1uCe9tXW"
      },
      "source": [
        "- Show some *Articles* and their *Author*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIcO9Fay8Y5N"
      },
      "source": [
        "- Show some articles that talk about \"random forests\". Hint: use their *title* and *abstract* properties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9M2KLgp7fm2"
      },
      "source": [
        "- Get the total number of *Article*, *Author* and *Venue* in the database. Hint: use nodes' \"LABEL\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUWwPpGu7vM5"
      },
      "source": [
        "- Get the number of relationships for each type (*VENUE*, *CITED*, ...). Hint: use relationships' \"TYPE\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuInaqBV_g9Q"
      },
      "source": [
        "- Find the most cited *Article*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VffHp0AfANp9"
      },
      "source": [
        "- Find the Top 10 *Author*s with the most collaborations. We count one collaboration as one article written by several authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCTXHIp_A92l"
      },
      "source": [
        "- Find the *Author* with whom \"Salvatore Greco\" has co-authored the most with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wPADkaKKXZe"
      },
      "source": [
        "How could we use this last query as a basis to recommend future collaborations to Salvatore Greco? To make this easier, we will need to infer a graph of co-authorship."
      ]
    }
  ]
}