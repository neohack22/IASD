{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "! echo \"foooo\" > ./drive/MyDrive/titi"
      ],
      "metadata": {
        "id": "ST2vKAUoH9Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hfbGEJMQIXuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2Pqr3qLwwPH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch as th\n",
        "import torch.autograd as ag\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import math\n",
        "import pickle\n",
        "import gzip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch as th\n",
        "import torch.autograd as ag\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import math\n",
        "import pickle\n",
        "import gzip"
      ],
      "metadata": {
        "id": "aJq5Da2gDGZU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYFxXiq-wwPM"
      },
      "source": [
        "The goal is to set up a simple classifier for text and sentiment analysis. \n",
        "\n",
        "The goal of this lab session is to implement the model proposed by  Yoon Kim, published in 2014. This model is a sentence classifier based on Convolution. The original paper can be found [here](https://www.aclweb.org/anthology/D14-1181). It was then adapted to DNA sequence classification by [this paper](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1878-3). Of course, there exists pytorch and tensorflow implementations on the web. They are more or less correct and efficient. However, here it is important to do it yourself. The goal is to better understand pytorch and the convolution. \n",
        "\n",
        "The task is the binary classification of movie reviews. The dataset is a part of the imdb dataset. You can find the original dataset on the imdb website or a version on the kaggle website. For this lab session, we will use a preprocessed and reduced version. \n",
        "\n",
        "The road-map is to: \n",
        "- Load the data\n",
        "- step-by-step computation (debug)\n",
        "- Create a model to wrap the convolution and pooling \n",
        "\n",
        "\n",
        "\n",
        "# Data loading \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbH3o93EwwPP"
      },
      "source": [
        "Load the data : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rm5GanOEwwPQ"
      },
      "outputs": [],
      "source": [
        "# find the file imdb.pck.gz, and set the next variable accordingly\n",
        "filename = 'imdb.pck.gz'\n",
        "\n",
        "# if you are on colab (otherwise comment the next command): \n",
        "# you can download the file with the following line: \n",
        "! wget \"https://drive.google.com/uc?export=download&id=1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA\" -O imdb.pck.gz\n",
        "\n",
        "\n",
        "\n",
        "fp = gzip.open(filename,'rb')\n",
        "texts , labels, lexicon  = pickle.load(fp) \n",
        "\n",
        "print(type(texts), type(labels), type(lexicon))\n",
        "print(texts[0])\n",
        "print(\"nb examples : \", len(texts))\n",
        "VOCAB_SIZE = len(lexicon)\n",
        "print(\"Vocab size: \", VOCAB_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find the file imdb.pck.gz, and set the next variable accordingly\n",
        "filename = 'imdb.pck.gz'\n",
        "\n",
        "# if you are on colab (otherwise comment the next command):\n",
        "# you can download the file with the following line:\n",
        "! wget \"https://drive.google.com/uc?export=download&id=1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA\" -O imdb.pck.gz\n",
        "\n",
        "fp = gzip.open(filename, 'rb')\n",
        "texts, labels, lexicon = pickle.load(fp)\n",
        "\n",
        "print(type(texts), type(labels), type(lexicon))\n",
        "print(texts[0])\n",
        "print(\"no examples : \", len(texts)) #\"nb examples : \", len(texts))\n",
        "VOCAB_SIZE = len(lexicon)\n",
        "print(\"Vocab size: \", VOCAB_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9hp_hncDpzj",
        "outputId": "1a825124-d501-49da-9645-fca65097da65"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-06 13:34:59--  https://drive.google.com/uc?export=download&id=1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA\n",
            "Resolving drive.google.com (drive.google.com)... 142.250.148.102, 142.250.148.139, 142.250.148.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.250.148.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0k-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/sb8vnick3f5ldqbbcv1kntltnghhf0up/1649252100000/16692574002775380562/*/1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-04-06 13:35:00--  https://doc-0k-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/sb8vnick3f5ldqbbcv1kntltnghhf0up/1649252100000/16692574002775380562/*/1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA?e=download\n",
            "Resolving doc-0k-0o-docs.googleusercontent.com (doc-0k-0o-docs.googleusercontent.com)... 142.250.148.132, 2607:f8b0:4001:c54::84\n",
            "Connecting to doc-0k-0o-docs.googleusercontent.com (doc-0k-0o-docs.googleusercontent.com)|142.250.148.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1552309 (1.5M) [application/x-gzip]\n",
            "Saving to: ‘imdb.pck.gz’\n",
            "\n",
            "imdb.pck.gz         100%[===================>]   1.48M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-04-06 13:35:01 (109 MB/s) - ‘imdb.pck.gz’ saved [1552309/1552309]\n",
            "\n",
            "<class 'list'> <class 'torch.Tensor'> <class 'dict'>\n",
            "tensor([ 36,  25, 381,  10,  58,  21,  83])\n",
            "no examples :  30000\n",
            "Vocab size:  5002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "y0UcbpdtwwPR"
      },
      "source": [
        "You get 3 objects : \n",
        "- *texts*  : a list of tensors, each tensor represent a word sequence to classify. \n",
        "- *labels* : the class, positive or negative, of the corresponding text\n",
        "- *lexicon*: a dictionnary to map integers to real words\n",
        "Note that a reduced number of words are selected to build the vocabulary. The less frequent words are discarded are replaced by a specific form (*unk* for unknown)\n",
        "To read the text you can use for example the following code: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cDQHRIgwwPS"
      },
      "outputs": [],
      "source": [
        "def idx2wordlist(idx_array,lexicon): \n",
        "    l = []\n",
        "    for i in idx_array: \n",
        "        l.append(lexicon[i.item()])\n",
        "    return l\n",
        "print(texts[0].shape)\n",
        "for i in range(5): \n",
        "    print(idx2wordlist(texts[i+50],lexicon))\n",
        "print(\"------------\")\n",
        "for i in range(5): \n",
        "    print(idx2wordlist(texts[-i-2000],lexicon))\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def idx2wordlist(idx_array,lexicon):\n",
        "  l = []\n",
        "  for i in idx_array:\n",
        "    l.append(lexicon[i.item()])\n",
        "  return l\n",
        "print(texts[0].shape)\n",
        "for i in range(5):\n",
        "  print(idx2wordlist(texts[i+50], lexicon))\n",
        "print(\"------------\")\n",
        "for i in range(5):\n",
        "  print(idx2wordlist(texts[-i-2000], lexicon))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRPaGVLwF0A0",
        "outputId": "ace0bfd3-2cba-4777-e38a-31d017ae067e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7])\n",
            "['strong', 'drama']\n",
            "['please', 'remake', 'this', 'movie']\n",
            "['very', 'funny', '!']\n",
            "['great', 'series']\n",
            "['fun', 'movie']\n",
            "------------\n",
            "['absolute', 'waste', 'of', 'time']\n",
            "['the', 'worst', 'movie', 'ever', 'made']\n",
            "['slow', 'motion', 'picture', 'that', 'did', \"n't\", 'get', 'to', 'the', 'point']\n",
            "['there', 'are', 'good', 'bad', 'movies', 'and', 'there', 'are', 'bad', 'bad', 'movies', 'this', 'one', 'is', 'a', 'real', 'stinker']\n",
            "['<unk>', 'so', 'bad', 'its', 'funny']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-tNkFM6wwPT"
      },
      "source": [
        "# Embeddings and Convolution layers\n",
        "\n",
        "Unfortunately, an important part of the work is dedicated to playing with dimensions. This is true for pytorch, as well as tensorflow. Here the sequence of operation is \n",
        "- Embedding\n",
        "- Convolution (1D)\n",
        "- Pooling\n",
        "- Linear\n",
        "\n",
        "Moreover, things can be tricky if we want our model to work properly with mini-batch. \n",
        "\n",
        "\n",
        "A quick introduction on  the Embedding layer. The goal is to store a set of real vectors associated to each symbol (word) in the vocabulary. The layer requires : \n",
        "- num_embeddings: the vocabulary size or the number of words under consideration. Words are represented by an index (starting at 0)\n",
        "- embedding_dim : the dimension of the continous space (or the word embeddings. \n",
        "Implicitely a lookup matrix is created to store *num_embeddings* of *size embedding_dim*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SX0bO2ewwPU"
      },
      "outputs": [],
      "source": [
        "vocabSize = len(lexicon)\n",
        "h1 = 4 # dimension of embeddings, the input size for convolution\n",
        "h2 = 2 # output dimension (filter size) for the convolution\n",
        "embLayer = th.nn.Embedding(num_embeddings=vocabSize, embedding_dim=h1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabSize = len(lexicon)\n",
        "h1 = 4 # dimension of embeddings, the input size for convolution\n",
        "h2 = 2 # output dimension (filter size) for the convolution\n",
        "embLayer = th.nn.Embedding(num_embeddings=vocabSize, embedding_dim=h1)"
      ],
      "metadata": {
        "id": "UeSDKa5dGj1R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRby3k-ZwwPV"
      },
      "source": [
        "The inference or forward method expects a Tensor of word indices (LongTensor) and returns the word vectors associated to these indices. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iLRgvbOwwPV"
      },
      "outputs": [],
      "source": [
        "# Don't play a sentence, with only one word ! \n",
        "embs = embLayer(texts[0])\n",
        "print(\"the length of the sequence : \", len(texts[0]))\n",
        "print(embs.shape)\n",
        "print(embs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't play a sentence, with only one word!\n",
        "embs = embLayer(texts[0])\n",
        "print(\"the length of the sequence : \", len(texts[0]))\n",
        "print(embs.shape)\n",
        "print(embs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SI15tM0Is45",
        "outputId": "20a1510f-6030-4b43-8961-68c85367ea07"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the length of the sequence :  7\n",
            "torch.Size([7, 4])\n",
            "tensor([[ 0.3809,  0.3718,  1.4414, -0.3220],\n",
            "        [-0.0716, -0.8475,  0.0575,  3.2444],\n",
            "        [ 2.2061, -0.0684,  1.3121,  1.5937],\n",
            "        [-0.3186,  0.9530, -1.1698, -0.1269],\n",
            "        [ 0.6542, -2.1104, -0.3662,  1.0056],\n",
            "        [ 1.3688,  0.1469,  1.1925, -0.7378],\n",
            "        [-2.4269, -1.5562,  1.4260, -0.9702]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7FN-JqUwwPW"
      },
      "source": [
        "\n",
        "\n",
        "Look at the documentation of the Conv1d layer. Read it carefully and try to completely understand the following code. A convolution layer expects a tensor as input, with the following dimensions *B,D,L*: \n",
        "- B: size of the batch, the number of examples (here the number of sequence). For the moment we consider *B=1* (only one sequence)\n",
        "- D: the dimension of the vectors for each time step\n",
        "- L: the length of the input sequence (the number of time step)\n",
        "\n",
        "We must therefore modify the dimensions of the tensor generated by the embedding layer accordingly. \n",
        "\n",
        "A first solution could be: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rD3ac051wwPX"
      },
      "outputs": [],
      "source": [
        "tmp = embs.view(1,h1,-1)\n",
        "print(tmp.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = embs.view(1,h1,-1)\n",
        "print(tmp.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdfUak3GJIZR",
        "outputId": "dc8d26ad-ec82-4fef-d5eb-28b7af3eea1e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNz8AYYAwwPX"
      },
      "source": [
        "The shape is correct, but it is safer to check the consistency: the first time step should be the embedding of the first word of the sequence. Is that correct ? "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Toutes les convolutions fonctionnent avec des tenseurs à 3 dimensions.<br>\n",
        "B = 1 (mini batch à 1 pour 1 exemple?)<br>\n",
        "D = 4<br>\n",
        "L (longueur des séquences) = 7<br>\n",
        "Il faut donc convertir le tenseur et ajouter une dimension"
      ],
      "metadata": {
        "id": "M2qYJSB7PVX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKeXfLS-wwPY"
      },
      "outputs": [],
      "source": [
        "#### TODO : \n",
        "print(tmp[0,:,0]) # the embedding of the first time step\n",
        "#### \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tmp[0,:,0]) # the embedding of the first time step\n",
        "print(embs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1SL8Tg-JRKA",
        "outputId": "750275e5-fb74-410c-8666-4335b42b1056"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.3809,  3.2444, -1.1698,  0.1469], grad_fn=<SelectBackward0>)\n",
            "tensor([[ 0.3809,  0.3718,  1.4414, -0.3220],\n",
            "        [-0.0716, -0.8475,  0.0575,  3.2444],\n",
            "        [ 2.2061, -0.0684,  1.3121,  1.5937],\n",
            "        [-0.3186,  0.9530, -1.1698, -0.1269],\n",
            "        [ 0.6542, -2.1104, -0.3662,  1.0056],\n",
            "        [ 1.3688,  0.1469,  1.1925, -0.7378],\n",
            "        [-2.4269, -1.5562,  1.4260, -0.9702]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On se rend compte qu'il n'avait pas pris ce qu'il fallait, car a fait à chaque fois un décalage de 7, ce qui n'était pas ce qu'on voulait."
      ],
      "metadata": {
        "id": "VYeTNPDHQbBI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGc3JpHnwwPY"
      },
      "source": [
        "Find the good way to tranform embs in consistent way. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaPIM_vzwwPZ"
      },
      "outputs": [],
      "source": [
        "## TODO \n",
        "tmp = None ## <--Find the right way\n",
        "print(tmp.shape)\n",
        "print(tmp[0,:,0])\n",
        "## while  the expected value is : \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = embs.transpose(1,0)\n",
        "print(tmp.shape)\n",
        "#print(tmp[0,:0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFDqyvecQx-Z",
        "outputId": "18fb386d-6de0-4461-bb3b-4222d6e55639"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embs.shape)\n",
        "tmp = embs.transpose(1,0)\n",
        "print(tmp.shape)\n",
        "print(tmp[:,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asOVk8SERAD8",
        "outputId": "03b66575-687c-4f92-b485-00a45ff7f64f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7, 4])\n",
            "torch.Size([4, 7])\n",
            "tensor([ 0.3809,  0.3718,  1.4414, -0.3220], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "le premier vecteur est bon"
      ],
      "metadata": {
        "id": "JjNQyaomRWBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(embs.shape)\n",
        "tmp = embs.transpose(1,0).unsqueeze(0) #)\n",
        "print(tmp.shape)\n",
        "print(tmp[0,:0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJtn5NrLRU8n",
        "outputId": "0d95f071-8580-4724-db1b-9d05a0c08a52"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7, 4])\n",
            "torch.Size([1, 4, 7])\n",
            "tensor([], size=(0, 7), grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0gDjmYDwwPZ"
      },
      "source": [
        "Now we have a tensor to feed the convolution layer: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOyNZPvpwwPZ"
      },
      "outputs": [],
      "source": [
        "conv1 = th.nn.Conv1d(in_channels=4,out_channels=2,kernel_size=3)\n",
        "\n",
        "res = conv1(tmp)\n",
        "print(\"embs : \",embs.shape)\n",
        "print(\"tmp  : \",tmp.shape)\n",
        "print(\"conv : \",res.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv1 = th.nn.Conv1d(in_channels=4,out_channels=2,kernel_size=3) #Conv1d(in_channels=4,out_channels=2,kernel_size=3) # par défauit le stride est à 1\n",
        "\n",
        "res = conv1(tmp)\n",
        "print(\"embs : \",embs.shape)\n",
        "print(\"tmp : \",tmp.shape)\n",
        "print(\"conv : \",res.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EGinEoQSrzu",
        "outputId": "d4db3ecf-1f15-456c-ea31-29b5ead89539"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embs :  torch.Size([7, 4])\n",
            "tmp :  torch.Size([1, 4, 7])\n",
            "conv :  torch.Size([1, 2, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "on a 5 applications"
      ],
      "metadata": {
        "id": "a6vir69GTJag"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxpHkqM-wwPa"
      },
      "source": [
        "Draw what happens to better understand the obtained dimensions. \n",
        "\n",
        "Now if we add another parameter for padding (set to 1). What do you observe ? \n",
        "Play a bit with the *kernel_size* along with the *padding* to understand the interaction: \n",
        "- try kernel_size=3,padding=1 and (4,1)\n",
        "- (5,1) and (5,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3bIo2ynwwPa"
      },
      "outputs": [],
      "source": [
        "conv1 = th.nn.Conv1d(in_channels=h1,out_channels=h2,kernel_size=3,padding=1)\n",
        "tmp=embs.view(1,4,-1)\n",
        "res = conv1(tmp)\n",
        "print(embs.shape)\n",
        "print(tmp.shape)\n",
        "print(res.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv1 = th.nn.Conv1d(in_channels=h1,out_channels=h2,kernel_size=3,padding=1)\n",
        "tmp=embs.view(1,4,-1)\n",
        "res = conv1(tmp)\n",
        "print(embs.shape)\n",
        "print(tmp.shape)\n",
        "print(res.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qVbLSnmTSkw",
        "outputId": "4fd723f0-e956-4f06-f1fe-e27deaaafce8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7, 4])\n",
            "torch.Size([1, 4, 7])\n",
            "torch.Size([1, 2, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conv1 = th.nnConv1d(in_channels=h1,out_channels=h2,kernel_size=4,padding=1)\n",
        "#tmp=embs.view()"
      ],
      "metadata": {
        "id": "iw8qa9-jUaXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeB8z6BBwwPa"
      },
      "source": [
        "What do you propose for pooling ? \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UbiYoe1wwPa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxv, indices = res.max(dim=2) # max retourne 2 structures de données : le max et les indices qui l'ont déclenché afin de savoir vers qui les gradient doivent être retropropagés\n",
        "print(maxv.shape)\n",
        "print(res)\n",
        "print(maxv)\n",
        "print(indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GovxPm7kV74A",
        "outputId": "a2004017-5e9a-4b0a-e42b-b065679eb55e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2])\n",
            "tensor([[[-0.6849, -0.2787,  1.2437, -0.2522, -0.0681,  0.5586, -0.0309],\n",
            "         [-1.2937, -0.0363,  1.7093, -1.4702, -2.0846,  0.4261,  0.3271]]],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "tensor([[1.2437, 1.7093]], grad_fn=<MaxBackward0>)\n",
            "tensor([[2, 2]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool = nn.AdaptiveMaxPool1d(2) # extrait les 2 valeurs max par composante\n",
        "pool(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKuwkJ_XXaFs",
        "outputId": "5180b4a0-57e2-4474-8f9d-162aac446d0d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.2437, 0.5586],\n",
              "         [1.7093, 0.4261]]], grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool2 = nn.MaxPool1d(res.shape[2])\n",
        "pool2(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_cUolBKYY-s",
        "outputId": "c02a2510-79a7-4024-ba59-e3afe742fe0a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.2437],\n",
              "         [1.7093]]], grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yyh93zswwPb"
      },
      "source": [
        "## A class for our model\n",
        "\n",
        "The goal now is to write a class to implement the model with embeddings, convolution and pooling. Writing this class, allows you to wrap what you have seen so far. To debug the model, you can first play step-by-step with each layer to ensure you are right with dimensions (it was done earlier). Then, write the class and run the training to evaluate the result (this what we have to do now). \n",
        "\n",
        "The class inherits from an existing class of pytorch : *Module*. This means that *Conv1d_classifier* is a *Module*, but we add some peculiarities. For that purpose we \n",
        "can fill the following code: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4EgTaCKwwPb"
      },
      "outputs": [],
      "source": [
        "class Conv1d_classifier(nn.Module):\n",
        "    '''A text classifier:\n",
        "    - input = a list of word indices\n",
        "    - output = probability associated to a binary classification task\n",
        "    - vocab_size: the number of words in the vocabulary we want to embed\n",
        "    - embedding_dim: size of the word vectors\n",
        "    '''\n",
        "    def __init__(self, vocab_size, embedding_dim, feat_size=10, kernel_size=3,lmax=35):\n",
        "        super(Conv1d_classifier, self).__init__()\n",
        "        self.emb_dim = embedding_dim \n",
        "        # in the previous line, \n",
        "        # store the value of the parameter embedding_dim\n",
        "        # TODO : write the end of the constructor\n",
        "        # It is important to create here all the layers of the network. \n",
        "        # All layers that have paramaters should be attribute. \n",
        "        # For example: \n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # Go on and add the rest. \n",
        "        # TODO ... \n",
        "        \n",
        "        \n",
        "            \n",
        "    def forward(self, input):\n",
        "        # TODO\n",
        "        # if you need to run forward with the embedding layer, \n",
        "        # you can call it by self.embeddings \n",
        "        # TODO ... \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv1d_classifier(nn.Module):\n",
        "    '''A text classifier:\n",
        "    - input = a list of word indices\n",
        "    - output = probability associated to a binary classification task\n",
        "    - vocab_size: the number of words in the vocabulary we want to embed\n",
        "    - embedding_dim: size of the word vectors\n",
        "    '''\n",
        "    def __init__(self, vocab_size, embedding_dim, feat_size=10, kernel_size=3, padding=1):#,lmax=35):\n",
        "        super(Conv1d_classifier, self).__init__()\n",
        "        self.emb_dim = embedding_dim \n",
        "        # in the previous line, \n",
        "        # store the value of the parameter embedding_dim\n",
        "        # TODO : write the end of the constructor\n",
        "        # It is important to create here all the layers of the network. \n",
        "        # All layers that have paramaters should be attribute. \n",
        "        # For example: \n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # Go on and add the rest. \n",
        "        # TODO ... \n",
        "        self.conv = nn.Conv1d(embedding_dim, feat_size, kernel_size=kernel_size,padding=padding) #conv1d(embedding_dim, feat_size, kernel_size=kernel_size)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.lin = nn.Linear(feat_size,1)        \n",
        "        \n",
        "            \n",
        "    def forward(self, input): # L\n",
        "        # TODO\n",
        "        # if you need to run forward with the embedding layer, \n",
        "        # you can call it by self.embeddings \n",
        "        # TODO ... \n",
        "        out = self.embeddings(input) # L, D\n",
        "        out = out.transpose(1,0).unsqueeze(0) # 1,D,L\n",
        "        out = self.conv(out) # 1,D',L'\n",
        "        out = self.pool(out) # 1,D',1 -> 1,D\n",
        "        return self.lin(out.squeeze())"
      ],
      "metadata": {
        "id": "ZU0xa3gdYv9L"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pptzwt0PwwPb"
      },
      "outputs": [],
      "source": [
        "# Test the class: is everything in place:\n",
        "# A first classifier is built like : \n",
        "classifier = Conv1d_classifier(vocab_size=VOCAB_SIZE,embedding_dim=10)\n",
        "# The parameters of the classifier are randomly initialize, but we \n",
        "# can use it on a sequence : \n",
        "out = classif.forward(texts[0])\n",
        "print(out.shape) # the output has 2 dimensions \n",
        "print(out)\n",
        "\n",
        "# It is correct ? If not, correct the class to get the expected result. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the class: is everything in place:\n",
        "# A first classifier is built like : \n",
        "classifier = Conv1d_classifier(vocab_size=VOCAB_SIZE,embedding_dim=10)\n",
        "# The parameters of the classifier are randomly initialize, but we \n",
        "# can use it on a sequence : \n",
        "out = classifier.forward(texts[0]) #classif.forward(texts[0])\n",
        "print(out.shape) # the output has 2 dimensions \n",
        "print(out)\n",
        "\n",
        "# It is correct ? If not, correct the class to get the expected result. \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9raF-sRaANe",
        "outputId": "1458d6e6-bdd9-49bd-e103-4eb949630e79"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1])\n",
            "tensor([0.5642], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4NOPa_fwwPc"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "To train the model, we need to define a loss function and an optimizer. For the moment we will rely on an online learning algorithm: online stochastic gradient descent. Like the previous lab session: \n",
        "- we pick one training example\n",
        "- compute the loss\n",
        "- back-propagation of the gradient \n",
        "- update of the parameters\n",
        "\n",
        "\n",
        "At the end of one epoch, we evaluate the model on the validation step. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V2ge3u8wwPc"
      },
      "outputs": [],
      "source": [
        "# Define the training loss \n",
        "loss_function = nn.BCELoss()\n",
        "# The optimizer \n",
        "optimizer = th.optim.Adam(classif1.parameters(), lr=0.01)\n",
        "# Handle the randomization of the training data \n",
        "total = len(texts)\n",
        "ntrain = 20000  # the number of texts for training \n",
        "assert(total > ntrain) # be sure it is correct\n",
        "## \n",
        "randomidx = list(range(total))\n",
        "random.shuffle(randomidx)\n",
        "## random selection of training examples \n",
        "trainidx  = randomidx[:ntrain]\n",
        "## and for validation \n",
        "valididx  = randomidx[ntrain:]\n",
        "## \n",
        "Nepoch = 10 # the number of training epochs \n",
        "for e in range(Nepoch): \n",
        "    # randomized the training set \n",
        "    random.shuffle(trainidx)\n",
        "    for i in trainidx:\n",
        "        # TODO : training\n",
        "        # \n",
        "    ## validation score \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Conv1d_classifier(vocab_size=VOCAB_SIZE,embedding_dim=10)\n",
        "# Define the training loss \n",
        "#loss_function = nn.BCELoss()\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "# The optimizer \n",
        "optimizer = th.optim.Adam(classifier.parameters(), lr=0.01) #classif1.parameters(), lr=0.01)\n",
        "# Handle the randomization of the training data \n",
        "total = len(texts)\n",
        "#ntrain = 20000  # the number of texts for training \n",
        "#assert(total > ntrain) # be sure it is correct\n",
        "## \n",
        "randomidx = list(range(total))\n",
        "#random.shuffle(randomidx)\n",
        "## random selection of training examples \n",
        "#trainidx  = randomidx[:ntrain]\n",
        "## and for validation \n",
        "#valididx  = randomidx[ntrain:]\n",
        "## \n",
        "Nepoch = 10 # the number of training epochs \n",
        "#losses = th.zeros(Nepochs)\n",
        "losses = th.zeros(Nepoch)\n",
        "for epoch in range (Nepoch): #e in range(Nepoch): \n",
        "    total_loss = th.Tensor([0])\n",
        "    correct=0\n",
        "    # randomized the training set \n",
        "    random.shuffle(randomidx) #trainidx)\n",
        "    for i in randomidx: #trainidx:\n",
        "        # TODO : training\n",
        "        #\n",
        "        classifier.zero_grad()\n",
        "        x = texts[i]\n",
        "        probs = classifier(x)[0]\n",
        "        loss = loss_fn(probs, labels[i])\n",
        "        pred= probs>0.5\n",
        "        if pred.item() == labels[i].item() :\n",
        "          correct +=1\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.data\n",
        "    #  loss[epoch] = total_loss/total\n",
        "    losses[epoch] = total_loss/total\n",
        "    ## validation score \n",
        "    print(epoch, losses[epoch], 100.0*correct/total)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPtdp5GIbbLD",
        "outputId": "be913d4a-e82c-4a8d-b74a-0afdab867d2a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor(0.4794) 74.81666666666666\n",
            "1 tensor(0.4095) 80.42333333333333\n",
            "2 tensor(0.3907) 81.87666666666667\n",
            "3 tensor(0.3831) 82.53666666666666\n",
            "4 tensor(0.3756) 82.84666666666666\n",
            "5 tensor(0.3647) 83.78333333333333\n",
            "6 tensor(0.3573) 84.23\n",
            "7 tensor(0.3532) 84.81333333333333\n",
            "8 tensor(0.3464) 85.21\n",
            "9 tensor(0.3476) 85.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(range(len(losses)), losses)\n",
        "plt.plot(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "_0cP1J75dKBB",
        "outputId": "21aac4e4-272a-42b8-8aec-00426b9891f2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb852df8090>]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh4-bi0YwwPc"
      },
      "source": [
        "# State of the art model\n",
        "\n",
        "To have a better model, we should add convolution layers of different kernel size, as in the paper of Yoon Kim 2014. \n",
        "We can use kernels of size 3,5, and 7 for instance. Create a new class for this model. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OW_yTDDBwwPd"
      },
      "outputs": [],
      "source": [
        "# TODO "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxQabG8pwwPd"
      },
      "source": [
        "And finaly add dropout on the last layer hidden layer.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lntWb21AwwPd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwdeJs_KwwPd"
      },
      "source": [
        "# Mini-batch training\n",
        "\n",
        "It is really faster to train the model with mini-batch. The issue is that the input sequences are not of the same size. As a workaround, we can write a function that create the tensor  for a mini-batch. This function needs: \n",
        "- a reference of the data (here texts)\n",
        "- the maximum length of a sequence in the mini-batch\n",
        "- a list of the indices of the sequences we want to put in the mini-batch\n",
        "\n",
        "The function creates a tensor and fill it with the selected sequences, but : \n",
        "- if a sequence is shorter than the maximum length, we pad the sequence with zero values (fill the empty slots)\n",
        "- if the sequence is longer, just truncate it. \n",
        "This function returns a tensor of dimensions (B,Lmax) to be the input of the embedding layer of our model. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1txvRztwwPd"
      },
      "outputs": [],
      "source": [
        "# TODO "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEw1u9fRwwPe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "2_lab_imdb_text_convolution.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}