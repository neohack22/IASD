{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQsOAa6jNNsz"
      },
      "source": [
        "The goal is to set up a simple classifier for text and sentiment analysis. The task is the binary classification of movie reviews. The dataset is a part of the *imdb* dataset. You can find the original dataset on the [imdb website](https://www.imdb.com/interfaces/) or a version on the [kaggle website](https://www.kaggle.com/utathya/imdb-review-dataset). For this lab session, we will use a preprocessed version. \n",
        "\n",
        "\n",
        "The roadmap is:\n",
        "- Load, clean and setup the data (in practice this a very important step, for this lab we skip it). \n",
        "- Make it suitable for pytorch models\n",
        "- Define your own model\n",
        "- Experiments\n",
        "\n",
        "\n",
        "# The data \n",
        "\n",
        "Datasets are available in the cloud repository. There are 2 files, one for positive reviews (imdb.pos) and one for the negative ones (imdb.neg). There are  300000 examples of each class. \n",
        "\n",
        "Here two functions to load and clean the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08BpotGBNNs5"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import torch as th\n",
        "import torch.autograd as ag\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import math\n",
        "import pickle\n",
        "import gzip\n",
        "\n",
        "th.manual_seed(1) # set the seed "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import torch as th\n",
        "import torch.autograd as ag\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import math\n",
        "import pickle\n",
        "import gzip\n",
        "\n",
        "th.manual_seed(1) # set the seed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgxQIYQfNaQ6",
        "outputId": "6e277371-cd14-4d5f-ac5d-389206f52a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f20ac5a66b0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL50pyJFNNs6"
      },
      "source": [
        "# Data loading \n",
        "\n",
        "\n",
        "Load the data : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9w3SEyANNs6"
      },
      "outputs": [],
      "source": [
        "# find the file imdb.pck.gz, and set the next variable accordingly\n",
        "filename = 'imdb.pck.gz'  # avoir enregistré en pickle permet d'avoir les données après processing dans un format simple\n",
        "\n",
        "# You can download the file with the following line: \n",
        "# ! wget \"https://drive.google.com/uc?export=download&id=1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA\" -O imdb.pck.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find the file imdb.pck.gz, and set the next variable accordingly\n",
        "filename = 'imdb.pck.gz'\n",
        "\n",
        "# You can download the file with following line:\n",
        "! wget \"https://drive.google.com/uc?export=download&id=1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA\" -O imdb.pck.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdfkjPpGNvg9",
        "outputId": "d78b2940-1697-4e90-cb68-10a48ec8a648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-06 13:30:39--  https://drive.google.com/uc?export=download&id=1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA\n",
            "Resolving drive.google.com (drive.google.com)... 142.250.148.100, 142.250.148.102, 142.250.148.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.250.148.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0k-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/97skf4cho437v70rv3p1reig2sqmr9fq/1649251800000/16692574002775380562/*/1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-04-06 13:30:40--  https://doc-0k-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/97skf4cho437v70rv3p1reig2sqmr9fq/1649251800000/16692574002775380562/*/1199vdCPh5jCMBTWTSM9th0wqMNv2KSvA?e=download\n",
            "Resolving doc-0k-0o-docs.googleusercontent.com (doc-0k-0o-docs.googleusercontent.com)... 74.125.69.132, 2607:f8b0:4001:c08::84\n",
            "Connecting to doc-0k-0o-docs.googleusercontent.com (doc-0k-0o-docs.googleusercontent.com)|74.125.69.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1552309 (1.5M) [application/x-gzip]\n",
            "Saving to: ‘imdb.pck.gz’\n",
            "\n",
            "imdb.pck.gz         100%[===================>]   1.48M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-04-06 13:30:40 (74.4 MB/s) - ‘imdb.pck.gz’ saved [1552309/1552309]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "FI-eXGaTNNs7"
      },
      "source": [
        "Open the data with python and you will get 3 objects : \n",
        "- *texts*  : a list of tensors, each tensor represent a word sequence to classify. \n",
        "- *labels* : the class, positive or negative, of the corresponding text\n",
        "- *lexicon*: a dictionnary to map integers to real words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYVUzUSDNNs7"
      },
      "outputs": [],
      "source": [
        "fp = gzip.open(filename,'rb')\n",
        "texts , labels, lexicon  = pickle.load(fp)\n",
        "\n",
        "print(type(texts), type(labels), type(lexicon))\n",
        "print(texts[0])\n",
        "print(\"nb examples : \", len(texts))\n",
        "VOCAB_SIZE = len(lexicon)\n",
        "print(\"Vocab size: \", VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fp = gzip.open(filename, 'rb')\n",
        "#texts, labels, lexison = pickle.load(fp)\n",
        "texts, labels, lexicon = pickle.load(fp)\n",
        "\n",
        "print(type(texts), type(labels), type(lexicon))\n",
        "print(texts[0])\n",
        "print(\"nb examples : \", len(texts))\n",
        "VOCAB_SIZE = len(lexicon)\n",
        "print(\"Vocab size: \", VOCAB_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UzvNwgXOGE5",
        "outputId": "0ee4f961-1652-415f-b699-7a3c4b4bc7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> <class 'torch.Tensor'> <class 'dict'>\n",
            "tensor([ 36,  25, 381,  10,  58,  21,  83])\n",
            "nb examples :  30000\n",
            "Vocab size:  5002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4HJnn3rNNs7"
      },
      "source": [
        "Note that a reduced number of words are selected to build the vocabulary. The less frequent words are discarded are replaced by a specific form (*unk* for unknown).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLm9MQ40NNs8"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    print(\"word of index\", i , \" : \", lexicon[i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(\"word of index\", i, \" : \", lexicon[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abc5J1wjPjZ4",
        "outputId": "dc36126b-3766-4176-e9a8-2914abdb6336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word of index 0  :  <pad>\n",
            "word of index 1  :  <unk>\n",
            "word of index 2  :  !\n",
            "word of index 3  :  the\n",
            "word of index 4  :  a\n",
            "word of index 5  :  of\n",
            "word of index 6  :  movie\n",
            "word of index 7  :  and\n",
            "word of index 8  :  this\n",
            "word of index 9  :  to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQeeIxjUNNs8"
      },
      "source": [
        "To read the text you can use for example the following code: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2vNtDLpNNs9",
        "outputId": "65662e8a-2e05-41cf-90ba-49e13be9db15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7])\n",
            "Some positive reviews\n",
            "------------\n",
            "['strong', 'drama']\n",
            "['please', 'remake', 'this', 'movie']\n",
            "['very', 'funny', '!']\n",
            "['great', 'series']\n",
            "['fun', 'movie']\n",
            "Some negative reviews\n",
            "------------\n",
            "['absolute', 'waste', 'of', 'time']\n",
            "['the', 'worst', 'movie', 'ever', 'made']\n",
            "['slow', 'motion', 'picture', 'that', 'did', \"n't\", 'get', 'to', 'the', 'point']\n",
            "['there', 'are', 'good', 'bad', 'movies', 'and', 'there', 'are', 'bad', 'bad', 'movies', 'this', 'one', 'is', 'a', 'real', 'stinker']\n",
            "['<unk>', 'so', 'bad', 'its', 'funny']\n",
            "-----------\n",
            "A random sentence: \n",
            "['you', 'definitely', 'need', 'to', 'see', 'this', 'movie']\n"
          ]
        }
      ],
      "source": [
        "def idx2wordlist(idx_array,lexicon): \n",
        "    l = []\n",
        "    for i in idx_array: \n",
        "        l.append(lexicon[i.item()])\n",
        "    return l\n",
        "print(texts[0].shape)\n",
        "print(\"Some positive reviews\")\n",
        "print(\"------------\")\n",
        "for i in range(5): \n",
        "    print(idx2wordlist(texts[i+50],lexicon))\n",
        "print(\"Some negative reviews\")\n",
        "print(\"------------\")\n",
        "for i in range(5): \n",
        "    print(idx2wordlist(texts[-i-2000],lexicon))\n",
        "    \n",
        "print(\"-----------\\nA random sentence: \")\n",
        "print(idx2wordlist(texts[104],lexicon))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def idx2wordlist(idx_array, lexicon):\n",
        "  l = []\n",
        "  for i in idx_array:\n",
        "    l.append(lexicon[i.item()])\n",
        "  return l\n",
        "print(texts[0].shape)\n",
        "print(\"Some positive reviews\")\n",
        "print(\"------------\")\n",
        "for i in range(5):\n",
        "  print(idx2wordlist(texts[-i-2000], lexicon))\n",
        "\n",
        "print(\"-----------\\nA random sentence: \")  \n",
        "print(idx2wordlist(texts[104], lexicon))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZDP3JdePuZV",
        "outputId": "104a775d-3626-4fb7-dc5e-fa33c992c6cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7])\n",
            "Some positive reviews\n",
            "------------\n",
            "['absolute', 'waste', 'of', 'time']\n",
            "['the', 'worst', 'movie', 'ever', 'made']\n",
            "['slow', 'motion', 'picture', 'that', 'did', \"n't\", 'get', 'to', 'the', 'point']\n",
            "['there', 'are', 'good', 'bad', 'movies', 'and', 'there', 'are', 'bad', 'bad', 'movies', 'this', 'one', 'is', 'a', 'real', 'stinker']\n",
            "['<unk>', 'so', 'bad', 'its', 'funny']\n",
            "-----------\n",
            "A random sentence: \n",
            "['you', 'definitely', 'need', 'to', 'see', 'this', 'movie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6SVRHS9NNs-"
      },
      "source": [
        "# Interface data/model\n",
        "\n",
        "In pratice, we start from raw texts and we need to convert them into word indices. At this step, we can perform text pre-processing, tokenization and data cleaning. In the present case, it is already done. But in real life it is a very important step. \n",
        "\n",
        "\n",
        "The goal is to implement a CBOW (Continuous Bag of Words, or a bag of word embeddings) classifier.  This means that the first layer of the model deals with word embeddings. \n",
        "\n",
        "The **Embedding** module in pytorch is designed for that purpose. This module expects as input an array or a list of word indices. For this session, the goal is to quickly develop a model. The data interface is therefore rather simple. \n",
        "We end this section by creating a labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wez3w2VhNNs-"
      },
      "source": [
        "# A first model\n",
        "The first model is a CBOW (Continuous Bag of Words). A text is represented as set of words (a bag of binary features):   \n",
        "- Each word is associated to its embedding. \n",
        "- The text is  represented as the sum of the word embeddings involved. \n",
        "- This sum of embeddings is then feed to linear layer with one output unit, \n",
        "- followed by the sigmoid activation. The model output is similar to a logistic regression. \n",
        "\n",
        "Now we want to code this in pytorch. One way is to first try to build such model (or a toy but similar example) **step by step**, then to create a nice class to wrap everything in a **model**. \n",
        "\n",
        "## Building the model, step by step\n",
        "\n",
        "The input layer of the model is an Embedding layer. This is already implemented in pytorch. Look at the following toy example: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvC6szlENNs_"
      },
      "outputs": [],
      "source": [
        "# build an Embedding layer\n",
        "# it is important to understand the parameters given to the constructor ! \n",
        "embLayer = th.nn.Embedding(num_embeddings=len(lexicon), embedding_dim=4) # je dis de créer un embedding layer de la taille du lexicon avec une dimension à 4 afin de visualiser\n",
        "# The dim of 4 is a toy example. \n",
        "# run forward on some input\n",
        "inp = texts[104] # on applique l'embedding layer à une ligne au hasard\n",
        "embs = embLayer(inp)\n",
        "# Look at the dimension of i/o\n",
        "print(\"The input: \",inp)\n",
        "print(\"length: \",len(inp))\n",
        "print(\"Embs shape : \",embs.shape)\n",
        "print(embs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build an Embedding layer : initialisation random\n",
        "# it is important to understand the parameters given to the constructor !\n",
        "D=4\n",
        "embLayer = th.nn.Embedding(num_embeddings=len(lexicon), embedding_dim=D) #4) #je récupère un modèle pytorch avec 5002 vecteurs de taille 4\n",
        "# The dim of 4 is a toy example.\n",
        "# run forward on some input\n",
        "inp = texts[104]\n",
        "embs = embLayer(inp) # quand j'appelle la fonction forward sur mon entrée, ~ embLayer.forward(inp) car tous les modules pytorch ont une fonction forward : prend les vecteurs (indices ayant remplacés les mots) du tenseur d'entrée auxquels il répond respectivement par les lignes du tenseur de sortie qui sont les embeddings associés\n",
        "# Look at the dimension of i/o\n",
        "print(\"The input; \",inp)\n",
        "print(\"length: \",len(inp))\n",
        "print(\"Embs shape : \",embs.shape)\n",
        "print(embs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcs9GUCYTjT6",
        "outputId": "7afcd2fe-20d8-4c73-aa83-d03ad1d15e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input;  tensor([ 21, 316, 320,   9,  59,   8,   6])\n",
            "length:  7\n",
            "Embs shape :  torch.Size([7, 4])\n",
            "tensor([[-1.4344, -0.5008,  0.1716, -0.1600],\n",
            "        [ 1.7762,  0.1760,  0.5085, -0.0357],\n",
            "        [-1.1876, -1.0616,  0.6630, -1.0036],\n",
            "        [ 0.1991,  0.0457,  0.1530, -0.4757],\n",
            "        [ 1.7241, -2.3648, -0.9295,  0.2936],\n",
            "        [ 1.8793, -0.0721,  0.1578, -0.7735],\n",
            "        [ 1.1017, -0.1759, -2.2456, -1.4465]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G-Xp9yMNNs_"
      },
      "source": [
        "Now, we want to compress the resulting tensor along the time dimension. This dimension depends on the input texts, while we want to build a fixed-size representation of the sentence. The sum is a first idea. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyEPYnbXNNs_"
      },
      "outputs": [],
      "source": [
        "## compute the sum of out to create a vector of size \"embedding_dim\".\n",
        "## Of course it will be a tensor with one dimension set to \"embedding_dim\".\n",
        "sumOfEmbs = None # TODO \n",
        "print(sumOfEmbs.shape) # check the shape "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## compute the sum of out to create a vector of size \"embedding_dim\".\n",
        "## Of course it will be a tensor with one dimension set to \"embedding_dim\".\n",
        "sumOfEmbs = embs.sum(dim=0) # la dimension des lignes va être compréssée et disparaitres\n",
        "# sumOfEmbs = embs.sum() # somme selon les 2 dimensions\n",
        "print(sumOfEmbs.shape) # check the shape\n",
        "\n",
        "#sumOfEmbs = embs.sum(dim=1) # somme selon les colonnes donne un vecteur de taille 7, qui n'est pas ce qu'on veut\n",
        "#print(sumOfEmbs.shape) # check the shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R_q5EV4UTLI",
        "outputId": "f3f56c30-ca2e-4adf-f827-38aec3c36bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL_k2f8aNNs_"
      },
      "source": [
        "The final layer is a linear transformation: as input we have a vector of size *embedding_dim* and 1 in output. \n",
        "Code this transformation and check the shape of the final result. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzRhBcDVNNtA"
      },
      "outputs": [],
      "source": [
        "# Compute out, after you created the Linear layer \n",
        "out= None \n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute out, after you created the Linear layer \n",
        "W = th.nn.Linear(in_features = D, out_features=1) # important de savoir de quelles dimensions on a besoin : la 1ère est la dimension d'entrée, puis celle de sortie, avec éventuellement un vecteur de biais\n",
        "out_activation = th.nn.Sigmoid() # à chaque construction de couche linéaire, l'initialisation est random car le nombre du tirage aléatoire après le seed est différent\n",
        "out= out_activation(W(sumOfEmbs)) #th.sigmoid(W(sumOfEmbs)) #None\n",
        "print(out.shape,out) #)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh6tdEeOX4nK",
        "outputId": "f1b86b1d-6ce2-4223-a335-ef8c077161ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1]) tensor([0.2945], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su6YIfT5NNtA"
      },
      "source": [
        "##  Wrap everything in a nice module/model\n",
        "\n",
        "To implement the model, we propose to fill the following class. To write your own module, inherit from the *Module* class. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7VT3Dt_NNtA"
      },
      "outputs": [],
      "source": [
        "class CBOW_classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW_classifier, self).__init__()\n",
        "        # TODO \n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        # TODO\n",
        "        return None \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW_classifier(nn.Module): # classe dont on hérite\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(CBOW_classifier, self).__init__() # fait appel à la place mère\n",
        "    self.emb = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lin =nn.Linear(embedding_dim, 1)#= nn.Linear(embedding_dim, 1)\n",
        "\n",
        "  def forward(self, inp): #inputs):\n",
        "    # pour définir la fonction forward, on va reprendre au propre la fonction que l'on vient de faire\n",
        "    return th.sigmoid(self.lin(self.emb(inp).sum(dim=0))) #None"
      ],
      "metadata": {
        "id": "g0e1p35nakV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "sw_7yrSDNNtA"
      },
      "source": [
        "This class inherits of *Module*. These two methods are mandatory. The constructor build a model with its initialized parameters. The *forward* is for inference.  Reminder: in pytorch, a model takes *Tensors (variables) * and returns *Tensors (variables)*. The output is compared with the gold standard by the loss function. \n",
        "\n",
        "Fill this class and make a simple test: take a training example and see if the forward pass is correct. The result should be a *FloatTensor* with one value: the score between 0 and 1 assigned by the model to the example. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9DUya_8NNtA",
        "outputId": "3ec8ec8e-ffe2-4f4b-9349-bcd7858c35c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1457], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "classifier = CBOW_classifier(vocab_size=len(lexicon),embedding_dim=10)\n",
        "print(classifier(texts[0]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = CBOW_classifier(vocab_size=len(lexicon), embedding_dim=10)\n",
        "print(classifier(texts[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0z2xGcqzTC8",
        "outputId": "e5764408-9e19-4bb0-ae05-36a039359c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8770], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels[0]) # tenseur qui stocke dans l'autre cas un tenseur scalaire donc mettre à la même dimension? si on ne fait pas mini-batch?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nReyXNbi7LpO",
        "outputId": "5ed8b8a3-f7a0-416f-ebd4-1b0d0a2400b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classifier.forward(texts[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmDBL7ir0bfb",
        "outputId": "b6e1f2dc-10cd-49ed-b811-4f8bdffd781f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8770], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI-q1vZUNNtA"
      },
      "source": [
        "## Objective function\n",
        "The loss (or objective) function is tailored to the model and the task.  \n",
        "\n",
        "- Read the doc of module **nn** : http://pytorch.org/docs/master/nn.html. \n",
        "- In our case, two loss functions can be used:  *BCELoss* and *BCEWithLogitsLoss*. Compare them and make your choice. \n",
        "- Given this choice, you may want to modify the class *CBOW_Classifier*. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZORm4wJ5NNtB"
      },
      "outputs": [],
      "source": [
        "## TODO : define de training function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the training finction\n",
        "loss_fn = nn.BCELoss() # car sigmoid # peut aussi être mis directement dans la classe # faut cohérence entre loss et réseau"
      ],
      "metadata": {
        "id": "t6-2B-zs3HhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "bdIITkkiNNtB"
      },
      "source": [
        "## Training \n",
        "\n",
        "Write the code to train your model and monitor the training process and to evaluate the model using test data. Starts with a SGD optimizer with 0.1 as learning rate. \n",
        "\n",
        "### Random order\n",
        "In many cases, in can be important to iter on the data in a random order and not in the order we built the corpus. This initial order can introduce bias in the evaluation process.  A simple method to shuffle the data is to shuffle the indices we use. Assume we have 10 training samples, we can do something like \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8Vpw4KxNNtB"
      },
      "outputs": [],
      "source": [
        "ids = list(range(10))\n",
        "import random \n",
        "random.shuffle(ids)\n",
        "for i in ids: \n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = list(range(10))\n",
        "import random\n",
        "random.shuffle(ids)\n",
        "for i in ids:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX7_EYfQ4ipW",
        "outputId": "ef8a90dc-95a9-4dd6-934c-902d9bbcfd72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "5\n",
            "2\n",
            "0\n",
            "3\n",
            "4\n",
            "7\n",
            "9\n",
            "1\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jbF71buNNtB"
      },
      "source": [
        "Now we have everything to run the training loop and test this model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFel-6fdNNtB"
      },
      "outputs": [],
      "source": [
        "## TODO: training loop\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "on devrait normalement regarder l'évolution"
      ],
      "metadata": {
        "id": "afQ1nO1e7-2W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkRuvgfFNNtB",
        "outputId": "8443bf49-8435-4c68-fd13-8780fd3f8e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor(0.7295) 52.513333333333335 tensor(15052.)\n",
            "1 tensor(0.6995) 57.653333333333336 tensor(15350.)\n",
            "2 tensor(0.6656) 61.97666666666667 tensor(15187.)\n",
            "3 tensor(0.6359) 65.23 tensor(15169.)\n",
            "4 tensor(0.6147) 67.07666666666667 tensor(14975.)\n",
            "5 tensor(0.5966) 68.39666666666666 tensor(14993.)\n",
            "6 tensor(0.5781) 69.98666666666666 tensor(14842.)\n",
            "7 tensor(0.5638) 71.18 tensor(14980.)\n",
            "8 tensor(0.5514) 72.00333333333333 tensor(14895.)\n",
            "9 tensor(0.5397) 72.89333333333333 tensor(14902.)\n"
          ]
        }
      ],
      "source": [
        "total = len(texts)\n",
        "randomidx = list(range(total))\n",
        "preds = th.zeros(total)\n",
        "#optimizer = th.optim.Adam(lr=1e-2) # je défini l'optim pour qu'il prenne tous les params, qui ne bougent pas car sgd?\n",
        "optimizer = th.optim.SGD(classifier.parameters(),lr=1e-2)\n",
        "Nepochs = 10\n",
        "losses = th.zeros(Nepochs)\n",
        "for epoch in range(Nepochs): #10):\n",
        "  total_loss = th.Tensor([0]) \n",
        "  correct=0\n",
        "  random.shuffle(randomidx) # parcours aléatoire des données accéléré grâce au parcours de leur indice plutôt\n",
        "  for i in randomidx:\n",
        "    classifier.zero_grad() # remet à 0 tout le stockage des grad dans les différents params\n",
        "    x = texts[i]\n",
        "    \n",
        "    probs = classifier(x)[0] # je fais passer un text dans le classifieur pour faire l'inférence : la fonction obj loss attend d'avoir 2 tenseurs qui soient de la même taille\n",
        "    loss = loss_fn(probs, labels[i]) # loss de la proba que ça ait un bon label\n",
        "    pred=probs>0.5 # taux de réussite\n",
        "    preds[i] = pred\n",
        "    if pred.item() == labels[i].item(): # sur un tenseur, quand on a une valeur, le .item permet de renvoyer un scalaire quoi qu'il advienne : on compare la prédiction au vrai label\n",
        "      correct += 1\n",
        "    loss.backward()\n",
        "    optimizer.step() # pas d'optimisation après la retro du gradient\n",
        "    total_loss += loss.data\n",
        "  losses[epoch] = total_loss/total    \n",
        "  print(epoch, losses[epoch], 100.0*correct/total, preds.sum()) #précision #total_losses[epoch], 100.0*correct/total, preds.sum()) #[epoch], 100.0*correct/total, preds.sum()) #0]/total, 100.0*correct/total, preds.sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "on commence un peu mieux qu'une chance sur 2"
      ],
      "metadata": {
        "id": "oKdIi765-KCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Vyp65rR93Bn",
        "outputId": "64e0ac1c-9b6b-4aba-f9fd-7d122cacc3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f20a46e7690>]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwU3eI4GNNtB"
      },
      "source": [
        "# First Experiments\n",
        "\n",
        "- Make experiments  with  2000 to start then all the data for training (equally distributed between positive and negative examples). \n",
        "- You should create a development and test sets. \n",
        "- Test different parametrization of the model (here the embedding size) and the hyper-parameter (the learning rate) for each setups. \n",
        "- Compare these different setups (loss function on the train and also the classification accuracy). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J2JZCSiNNtC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8_98lNyNNtC"
      },
      "source": [
        "# A deeper model\n",
        "\n",
        "We can add a hidden layer to the previous classifier. \n",
        "- Do the same as before with the different setups\n",
        "- Find the good choice of hyper-parameters.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubNcAoOoNNtC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "1_lab_imdb.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}