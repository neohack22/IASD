{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neohack22/IASD/blob/prerequisites/tensorflow/tutorials/load_data/numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pixDvex9KBqt"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K16pBM8mKK7a"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfRdquslKbO3"
      },
      "source": [
        "# Load NumPy data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uq3F0ggKlZb"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/load_data/numpy\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/load_data/numpy.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/numpy.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/load_data/numpy.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0tqX8qkXZEj"
      },
      "source": [
        "This tutorial provides an example of loading data from NumPy arrays into a `tf.data.Dataset`.\n",
        "\n",
        "This example loads the MNIST dataset from a `.npz` file. However, the source of the NumPy arrays is not important.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ze5IBx9clLB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6J3JzK5NxQ6"
      },
      "outputs": [],
      "source": [
        " \n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "G7Gj24JRlAWj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0yWiN8-cpDb"
      },
      "source": [
        "### Load from `.npz` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLHNrFM6RWoM"
      },
      "outputs": [],
      "source": [
        "DATA_URL = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n",
        "\n",
        "path = tf.keras.utils.get_file('mnist.npz', DATA_URL)\n",
        "with np.load(path) as data:\n",
        "  train_examples = data['x_train']\n",
        "  train_labels = data['y_train']\n",
        "  test_examples = data['x_test']\n",
        "  test_labels = data['y_test']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_URL = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n",
        "\n",
        "path = tf.keras.utils.get_file('mnist.npz', DATA_URL)\n",
        "with np.load(path) as data:\n",
        "  train_examples = data['x_train']\n",
        "  train_labels = data['y_train']\n",
        "  test_examples = data['x_test']\n",
        "  test_labels = data['y_test']"
      ],
      "metadata": {
        "id": "VcUJ6i8_lFak",
        "outputId": "6b9d64e9-6979-47de-c938-4e22460a67bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCeCkvrDgCMM"
      },
      "source": [
        "## Load NumPy arrays with `tf.data.Dataset`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tslB0tJPgB-2"
      },
      "source": [
        "Assuming you have an array of examples and a corresponding array of labels, pass the two arrays as a tuple into `tf.data.Dataset.from_tensor_slices` to create a `tf.data.Dataset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN_8wwc5R7Qm"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "        train_examples, train_labels\n",
        "    )\n",
        ")\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "        test_examples, test_labels\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "wTLwmbUSlnl8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rco85bbkDfN"
      },
      "source": [
        "## Use the datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dvl1uUukc4K"
      },
      "source": [
        "### Shuffle and batch the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTXdRMPcSXZj"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "Xd8l5pnYl5mV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w69Jl8k6lilg"
      },
      "source": [
        "### Build and train a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uhxr8py4DkDN"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['sparse_categorical_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Flatten(\n",
        "         input_shape=(28,28)\n",
        "     ),\n",
        "     tf.keras.layers.Dense(\n",
        "         128, activation='relu'\n",
        "     ),\n",
        "     tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.RMSprop(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True\n",
        "    ),\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "uqLadr2emN7t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLDzlPGgOHBx"
      },
      "outputs": [],
      "source": [
        "model.fit(train_dataset, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, epochs=10)"
      ],
      "metadata": {
        "id": "OU2LLtmLm4zV",
        "outputId": "6c22c89c-55a4-4b98-88b7-34818a0a2f27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.6124 - sparse_categorical_accuracy: 0.8825\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.5700 - sparse_categorical_accuracy: 0.9287\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.3867 - sparse_categorical_accuracy: 0.9484\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.3364 - sparse_categorical_accuracy: 0.9556\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.2792 - sparse_categorical_accuracy: 0.9616\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.2568 - sparse_categorical_accuracy: 0.9657\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.2562 - sparse_categorical_accuracy: 0.9693\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.2156 - sparse_categorical_accuracy: 0.9722\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.2020 - sparse_categorical_accuracy: 0.9745\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.1915 - sparse_categorical_accuracy: 0.9762\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd58694e410>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2q82yN8mmKIE"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "x7k5SEHkm8gj",
        "outputId": "43635540-72cb-489c-d54d-a95f50670ed2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 0s 2ms/step - loss: 0.7124 - sparse_categorical_accuracy: 0.9544\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7123614549636841, 0.9544000029563904]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QGtpaPePm-00"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "numpy.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}